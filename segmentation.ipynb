{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from transformers import MarkupLMFeatureExtractor, MarkupLMProcessor, MarkupLMForTokenClassification\n",
    "from bs4 import BeautifulSoup\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "\n",
    "id2label = {1: \"BEGIN\", 0: \"OTHER\"}\n",
    "label2id = {\"BEGIN\": 1, \"OTHER\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_folder(folder_path : str):\n",
    "    '''\n",
    "        This function loading all json files from folder.\n",
    "        Each file contains dict with labels and its values.\n",
    "        Each file must contains \"html\" label with its html code. \n",
    "        Each file must contains \"xpaths\" label with its labeled xpaths list. \n",
    "        \n",
    "    '''\n",
    "    extractor = MarkupLMFeatureExtractor()\n",
    "    \n",
    "    folder_path = os.path.abspath(folder_path)\n",
    "    files_path = glob(os.path.join(folder_path, \"*.json\"))\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for file_path in files_path:\n",
    "        print(file_path)\n",
    "        with open(file_path) as file:\n",
    "            info = json.load(file)\n",
    "            \n",
    "        html = info[\"html\"]\n",
    "        labeled_xpaths = info[\"xpaths\"]\n",
    "\n",
    "        encoding = extractor(html)\n",
    "            \n",
    "        \n",
    "        labels = []\n",
    "        \n",
    "        for xpath in encoding[\"xpaths\"][0]:\n",
    "            if xpath in labeled_xpaths:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "\n",
    "\n",
    "        print(len(labels))\n",
    "        print([_ for _ in labels if _ != 0])\n",
    "        \n",
    "        labels = [labels]\n",
    "        print(len(encoding['nodes'][0]), len(encoding['xpaths'][0]), len(labels[0]))\n",
    "        data.append({'nodes': encoding['nodes'],\n",
    "                     'xpaths': encoding['xpaths'],\n",
    "                     'node_labels': labels,\n",
    "                     'html': html})\n",
    "        \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_from_folder(\"test_dataset/train_part\")\n",
    "valid_data = load_from_folder(\"test_dataset/test_part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for node, label in zip(valid_data[idx]['nodes'][0], valid_data[idx]['node_labels'][0]):\n",
    "  if id2label[label] != 'OTHER':\n",
    "    print(node, id2label[label])\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициалиация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkupLMDataset(Dataset):\n",
    "    \"\"\"Dataset for token classification with MarkupLM.\"\"\"\n",
    "\n",
    "    def __init__(self, data, processor=None):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # first, get nodes, xpaths and node labels\n",
    "        item = self.data[idx]\n",
    "        nodes, xpaths, node_labels = item['nodes'], item['xpaths'], item['node_labels']\n",
    "\n",
    "        # provide to processor\n",
    "        encoding = self.processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        # remove batch dimension\n",
    "        encoding = {k: v.squeeze() for k, v in encoding.items()}\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = MarkupLMProcessor.from_pretrained(\"microsoft/markuplm-base\", truncation = True)\n",
    "processor.parse_html = False\n",
    "\n",
    "train_set = MarkupLMDataset(data=train_data, processor=processor)\n",
    "valid_set = MarkupLMDataset(data=valid_data, processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = valid_set[0]\n",
    "for k,v in example.items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, label in zip(example['input_ids'].tolist(), example['labels'].tolist()):\n",
    "    # if label != -100:\n",
    "    #     print(processor.decode([id]), label)\n",
    "    if label == 1:\n",
    "        print(processor.decode([id]), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=3, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MarkupLMForTokenClassification.from_pretrained(\"microsoft/markuplm-base\", id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"B-\" + x for x in list(id2label.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def get_labels(predictions, references):\n",
    "    # Transform predictions and references tensos to numpy arrays\n",
    "    if device.type == \"cpu\":\n",
    "        y_pred = predictions.detach().clone().numpy()\n",
    "        y_true = references.detach().clone().numpy()\n",
    "    else:\n",
    "        y_pred = predictions.detach().cpu().clone().numpy()\n",
    "        y_true = references.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(pred, gold_label) if l != -100]\n",
    "        for pred, gold_label in zip(y_pred, y_true)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(pred, gold_label) if l != -100]\n",
    "        for pred, gold_label in zip(y_pred, y_true)\n",
    "    ]\n",
    "    return true_predictions, true_labels\n",
    "\n",
    "def compute_metrics(return_entity_level_metrics=True):\n",
    "    results = metric.compute()\n",
    "    if return_entity_level_metrics:\n",
    "        # Unpack nested dictionaries\n",
    "        final_results = {}\n",
    "        for key, value in results.items():\n",
    "            if isinstance(value, dict):\n",
    "                for n, v in value.items():\n",
    "                    final_results[f\"{key}_{n}\"] = v\n",
    "            else:\n",
    "                final_results[key] = value\n",
    "        return final_results\n",
    "    else:\n",
    "        return {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "print(device)\n",
    "for epoch in range(10):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # get the inputs;\n",
    "        inputs = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(\"Loss:\", loss.item())\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "        preds, refs = get_labels(predictions, labels)\n",
    "        metric.add_batch(\n",
    "            predictions=preds,\n",
    "            references=refs,\n",
    "        )\n",
    "\n",
    "    eval_metric = compute_metrics()\n",
    "    print(f\"Epoch {epoch}:\", eval_metric)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import segmentation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "print(device)\n",
    "\n",
    "valid_metric = segmentation_metric()\n",
    "\n",
    "for record in tqdm(valid_data):\n",
    "    nodes = record['nodes']\n",
    "    xpaths = record['xpaths']\n",
    "    node_labels = record['node_labels']\n",
    "    \n",
    "    encoding = processor(nodes=nodes, xpaths=xpaths, node_labels=node_labels, return_offsets_mapping=True, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    offset_mapping = encoding.pop(\"offset_mapping\")\n",
    "    labels = encoding.pop(\"labels\")\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "\n",
    "    predictions = outputs.logits.argmax(dim=-1)\n",
    "    xpaths = batch[\"xpaths\"]\n",
    "    \n",
    "    valid_metric.add_result({\"true_xpaths\" : [xpath for idx, xpath in enumerate(xpaths) if node_labels[idx] == 1]})\n",
    "    \n",
    "print(valid_metric.get_metric())\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "markup-segmentation-03k7_eFX-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
